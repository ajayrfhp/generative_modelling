# -*- coding: utf-8 -*-
"""lsgan_vs_vanilla.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1mA5wiJ1N6CLvJLt8IDK2Wr78NnNxTIf-
"""

import torch
import torch.nn as nn
import torch.optim as optim
from torchvision import datasets, transforms
from torch.utils import data
import numpy as np
from matplotlib import pyplot as plt
from sklearn.model_selection import train_test_split

torch.set_default_tensor_type('torch.cuda.FloatTensor')
torch.cuda.current_device(), torch.cuda.device_count()

batch_size = 100

train_loader = torch.utils.data.DataLoader(
        datasets.MNIST('../data', train=True, download=True,
                       transform=transforms.Compose([
                           transforms.ToTensor(),
                           transforms.Normalize((0.5,), (0.5,))
                       ])),
        batch_size=batch_size, shuffle=True)

test_loader = torch.utils.data.DataLoader(
    datasets.MNIST('../data', train=False, transform=transforms.Compose([
                        transforms.ToTensor(),
                        transforms.Normalize((0.5,), (0.5,))
                    ])),
    batch_size=batch_size, shuffle=True)

train_loader, test_loader

??nn.ConvTranspose2d

class Generator(nn.Module):
  def __init__(self):
    '''
    Network is a map from one image to another image
    (Batch, 1, w, h) -> (Batch, 1, w, h)
    (Batch, 1, w, h) -> 2ConvDown -> Flatten -> FC -> Bottleneck -> FC -> Reshape -> 2ConvUp -> (Batch, 1, w, h)
    '''
    super(Generator, self).__init__()
    self.fc1 = nn.Linear(128, 256)
    self.fc2 = nn.Linear(256, 512)
    self.fc3 = nn.Linear(512, 1024)
    self.fc4 = nn.Linear(1024, 784)

  def forward(self, z):
    # Down
    z = self.fc1(z)
    z = nn.LeakyReLU(0.2)(z)
    z = self.fc2(z)
    z = nn.LeakyReLU(0.2)(z) 
    z = self.fc3(z)
    z = nn.LeakyReLU(0.2)(z)
    z = self.fc4(z)
    z = nn.Tanh()(z)
    z = z.view((-1, 1, 28, 28))
    return z 


class Discriminator(nn.Module):
  def __init__(self):
    '''
    Network is a map from an image to (0, 1)
    (Batch, 1, w, h) -> (Batch, )
    '''
    super(Discriminator, self).__init__()
    self.fc1 = nn.Linear(784, 1024)
    self.fc2 = nn.Linear(1024, 512)
    self.fc3 = nn.Linear(512, 256)
    self.fc4 = nn.Linear(256, 1)

  
  def forward(self, x):
    x = x.view((-1, 784))
    x = self.fc1(x)
    x = nn.LeakyReLU(0.2)(x)
    x = self.fc2(x)
    x = nn.LeakyReLU(0.2)(x)
    x = self.fc3(x)
    x = nn.LeakyReLU(0.2)(x)
    x = self.fc4(x)
    return (x)


generator = Generator()
discriminator = Discriminator()
generated = generator(torch.randn(10, 128))

predictions = discriminator(generated)
next(discriminator.parameters()).is_cuda

G = Generator()
D = Discriminator()

G_optimizer = optim.Adam(G.parameters(), lr = 1e-4)
D_optimizer = optim.Adam(D.parameters(), lr = 1e-4)


def train(G, D, G_optimizer, D_optimizer, train_loader, criterion):
  G_losses = []
  D_losses = []
  transform = transforms.Compose([
    transforms.Normalize(mean=[0.5,],
                         std=[0.5,])])
  D_grads = 0
  for i, (X, Y) in enumerate(train_loader):
    
    # train D
    Z = torch.randn((X.shape[0], 128))
    D.zero_grad()
    X = X.cuda()
    for p in D.parameters(): p.requires_grad = True
    D_loss = criterion(D(X), torch.ones((X.shape[0], 1))) + criterion(D(G(Z)), torch.zeros((X.shape[0], 1)))
    D_loss.backward(retain_graph=True)
    D_optimizer.step()

    # train G
    G.zero_grad()
    for p in D.parameters(): p.requires_grad = False
    
    G_loss = criterion(D(G(Z)), torch.ones((X.shape[0], 1)))

    G_loss.backward()
    G_optimizer.step()
    
    G_losses.append(G_loss.mean().item())
    D_losses.append(D_loss.mean().item())
    D_grads += sum([x.grad.sum() for x in D.parameters()])
  return D_grads.item()


def validate(G, D, test_loader):
  D_losses = []
  G_losses = []
  for i, (X, Y) in enumerate(test_loader):
    Z = torch.randn((X.shape[0], 128))
    X = X.cuda()
    D_loss = nn.BCEWithLogitsLoss()(D(X), torch.ones((X.shape[0], 1))) + nn.BCEWithLogitsLoss()(D(G(Z)), torch.zeros((X.shape[0], 1)))
    G_loss = nn.BCEWithLogitsLoss()(D(G(Z)), torch.ones((X.shape[0], 1)))
    D_losses.append(D_loss.item())
    G_losses.append(G_loss.item())
  return sum(D_losses) / len(D_losses), sum(G_losses) / len(G_losses)


vanilla_train_D_losses = []
vanilla_train_G_losses = []
vanilla_test_D_losses = []
vanilla_test_G_losses = []
vanilla_D_grads = []
for epoch in range(20):
  D_grads = train(G, D, G_optimizer, D_optimizer, train_loader, nn.BCEWithLogitsLoss())
  D_train_loss, G_train_loss = validate(G, D, train_loader)
  D_test_loss, G_test_loss = validate(G, D, test_loader)
  vanilla_train_D_losses.append(D_train_loss)
  vanilla_train_G_losses.append(G_train_loss)
  vanilla_test_D_losses.append(D_test_loss)
  vanilla_test_G_losses.append(G_test_loss)
  vanilla_D_grads.append(D_grads)
  print(epoch, D_train_loss, G_train_loss, D_test_loss, G_test_loss, D_grads)

G = Generator()
D = Discriminator()

G_optimizer = optim.Adam(G.parameters(), lr = 1e-4)
D_optimizer = optim.Adam(D.parameters(), lr = 1e-4)

def lsgan_train(G, D, G_optimizer, D_optimizer, train_loader):
  G_losses = []
  D_losses = []
  transform = transforms.Compose([
    transforms.Normalize(mean=[0.5,],
                         std=[0.5,])])
  D_grads = 0
  for i, (X, Y) in enumerate(train_loader):
    
    # train D
    Z = torch.randn((X.shape[0], 128))
    D.zero_grad()
    X = X.cuda()
    for p in D.parameters(): p.requires_grad = True
    D_loss = torch.mean((D(X) - 1) ** 2) + torch.mean(D(G(Z))** 2)
    D_loss.backward(retain_graph=True)
    D_optimizer.step()

    # train G
    G.zero_grad()
    for p in D.parameters(): p.requires_grad = False
    
    G_loss = torch.mean((D(G(Z)) - 1) ** 2)

    G_loss.backward()
    G_optimizer.step()
    
    G_losses.append(G_loss.mean().item())
    D_losses.append(D_loss.mean().item())
    D_grads += sum([x.grad.sum() for x in D.parameters()])
  return D_grads.item()


def lsgan_validate(G, D, test_loader):
  D_losses = []
  G_losses = []
  for i, (X, Y) in enumerate(test_loader):
    Z = torch.randn((X.shape[0], 128))
    X = X.cuda()
    D_loss = torch.mean((D(X) - 1) ** 2) + torch.mean(D(G(Z))** 2)
    G_loss = torch.mean((D(G(Z)) - 1) ** 2)
    D_losses.append(D_loss.item())
    G_losses.append(G_loss.item())
  return sum(D_losses) / len(D_losses), sum(G_losses) / len(G_losses)


lsgan_train_D_losses = []
lsgan_train_G_losses = []
lsgan_test_D_losses = []
lsgan_test_G_losses = []
lsgan_D_grads = []
for epoch in range(20):
  D_grads = lsgan_train(G, D, G_optimizer, D_optimizer, train_loader)
  D_train_loss, G_train_loss = lsgan_validate(G, D, train_loader)
  D_test_loss, G_test_loss = lsgan_validate(G, D, test_loader)
  lsgan_train_D_losses.append(D_train_loss)
  lsgan_train_G_losses.append(G_train_loss)
  lsgan_test_D_losses.append(D_test_loss)
  lsgan_test_G_losses.append(G_test_loss)
  lsgan_D_grads.append(D_grads)
  print(epoch, D_train_loss, G_train_loss, D_test_loss, G_test_loss, D_grads)

plt.figure(figsize=(7, 7))
plt.plot(range(0, 20), lsgan_train_D_losses, label = 'lsgan train d losses')
plt.plot(range(0, 20), lsgan_train_G_losses, label = 'lsgan test g losses')
plt.plot(range(0, 20), lsgan_test_D_losses, label = 'lsgan train d losses')
plt.plot(range(0, 20), lsgan_test_G_losses, label = 'lsgan test g losses')
plt.plot(range(0, 20), vanilla_train_D_losses, label = 'vanilla train d losses')
plt.plot(range(0, 20), vanilla_train_G_losses, label = 'vanilla test g losses')
plt.plot(range(0, 20), vanilla_test_D_losses, label = 'vanilla train d losses')
plt.plot(range(0, 20), vanilla_test_G_losses, label = 'vanilla test g losses')
plt.legend(loc='upper left')
plt.show()

plt.plot(range(0, 20), lsgan_D_grads, label = 'lsgan D Grads')
plt.plot(range(0, 20), vanilla_D_grads, label = 'vanilla D Grads')
plt.legend(loc='upper left')
plt.show()

def tensor2image(x):
  return x.detach().numpy().transpose(0, 2, 3, 1)

def image2tensor(x):
  return torch.tensor(x.transpose(0, 3, 1, 2))

def display_image(image):
  plt.figure(figsize=(1,1))
  plt.imshow(image[:,:,0], cmap = 'gray')
  plt.show()


transform = transforms.Compose([
  transforms.Normalize(mean=[0.5,],
                        std=[0.5,])])
inputs = torch.randn((10, 128))
print(inputs.shape)
predictions = G(inputs).cpu()
predictions_numpy = tensor2image(predictions.cpu())
for j, (inpt, prediction) in enumerate(zip(inputs, predictions_numpy)):
  print(inpt.sum(), prediction.sum())
  display_image(prediction)
  if j > 30:
    break

