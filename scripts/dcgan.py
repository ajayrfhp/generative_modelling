# -*- coding: utf-8 -*-
"""dcgan.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1pNI-gp7mn49Yiv2npKrClQAXJ8P3HwYz
"""

import torch
import torch.nn as nn
import torch.optim as optim
from torchvision import datasets, transforms
from torch.utils import data
import numpy as np
from matplotlib import pyplot as plt
from sklearn.model_selection import train_test_split

torch.set_default_tensor_type('torch.cuda.FloatTensor')
torch.cuda.current_device(), torch.cuda.device_count()

batch_size = 100

train_loader = torch.utils.data.DataLoader(
        datasets.MNIST('../data', train=True, download=True,
                       transform=transforms.Compose([
                           transforms.ToTensor(),
                           transforms.Normalize((0.5,), (0.5,))
                       ])),
        batch_size=batch_size, shuffle=True)

test_loader = torch.utils.data.DataLoader(
    datasets.MNIST('../data', train=False, transform=transforms.Compose([
                        transforms.ToTensor(),
                        transforms.Normalize((0.5,), (0.5,))
                    ])),
    batch_size=batch_size, shuffle=True)

train_loader, test_loader

??nn.ConvTranspose2d

class Generator(nn.Module):
  def __init__(self):
    '''
    Network is a map from noise vector to image
    (Batch, 128) -> (Batch, 1, w, h)
    '''
    super(Generator, self).__init__()
    self.fc1 = nn.Linear(128, 128)
    self.conv1T = nn.ConvTranspose2d(32, 32, 3, 2)
    self.conv2T = nn.ConvTranspose2d(32, 32, 3, 2)
    self.conv3T = nn.ConvTranspose2d(32, 32, 3, 2)
    self.conv4T = nn.ConvTranspose2d(32, 1, 3, 1, padding = 1)

  def forward(self, x):
    # UP
    x = self.fc1(x) # (Batch_size, 32 * 2 * 2)
    x = nn.LeakyReLU(0.1)(x) # (Batch_size, 32 * 2 * 2)
    x = x.view((-1, 32, 2, 2)) # (Batch_size, 32, 2, 2)
    x = self.conv1T(x, output_size = (x.shape[0], 32, 6, 6)) # (Batch_size, 32 * 6 * 6)
    x = nn.BatchNorm2d(32)(x) # (Batch_size, 32 * 6 * 6)
    x = nn.LeakyReLU(0.1)(x) # (Batch_size, 32, 6, 6)
    x = self.conv2T(x, output_size = (x.shape[0], 32 , 13, 13)) # (Batch_size, 32, 13, 13)
    x = nn.BatchNorm2d(32)(x) # (Batch_size, 32 * 13 * 13)
    x = nn.LeakyReLU(0.1)(x) # (Batch_size, 32, 13, 13)
    x = self.conv3T(x, output_size = (x.shape[0], 1 , 28, 28)) # (Batch_size, 1, 28, 28)
    x = nn.LeakyReLU(0.1)(x)
    x = self.conv4T(x, output_size = (x.shape[0], 1 , 28, 28)) # (Batch_size, 1, 28, 28)
  
    return nn.Tanh()(x)

class Discriminator(nn.Module):
  def __init__(self):
    '''
    Network is a map from an image to (0, 1)
    (Batch, 1, w, h) -> (Batch, )
    '''
    super(Discriminator, self).__init__()
    self.conv1 = nn.Conv2d(1, 32, 3, 2)
    self.conv2 = nn.Conv2d(32, 32, 3, 2)
    self.fc1 = nn.Linear(32 * 6 * 6, 128)
    self.output = nn.Linear(128, 1)

  def forward(self, x):
    x = self.conv1(x) # (Batch_size, 32, 13, 13)
    x = nn.LeakyReLU(0.2)(x) # (Batch_size, 32, 13, 13)
    x = self.conv2(x) # (Batch_size, 32, 6, 6)
    x = nn.LeakyReLU(0.2)(x) # (Batch_size, 32, 6, 6)
    x = x.reshape((-1, 32 * 6 * 6)) # (Batch_size, 32 * 6 * 6)
    x = self.fc1(x) # (Batch_size, 128)
    x = nn.LeakyReLU(0.2)(x) # (Batch_size, 128)
    x = self.output(x)
    return nn.Sigmoid()(x)


generator = Generator()
discriminator = Discriminator()
generated = generator(torch.randn(10, 128))

predictions = discriminator(generated)
next(generator.parameters()).is_cuda

G = Generator()
D = Discriminator()

G_optimizer = optim.Adam(G.parameters(), lr = 1e-4)
D_optimizer = optim.Adam(D.parameters(), lr = 1e-4)


def train(G, D, G_optimizer, D_optimizer, train_loader):
  G_losses = []
  D_losses = []
  transform = transforms.Compose([
    transforms.Normalize(mean=[0.5,],
                         std=[0.5,])])
  for i, (X, Y) in enumerate(train_loader):
    
    # train D
    Z = torch.randn((X.shape[0], 128))
    D.zero_grad()
    X = X.cuda()
    for p in D.parameters(): p.requires_grad = True
    D_loss = nn.BCELoss()(D(X), torch.ones((X.shape[0], 1))) + nn.BCELoss()(D(G(Z)), torch.zeros((X.shape[0], 1)))
    D_loss.backward(retain_graph=True)
    D_optimizer.step()

    # train G
    G.zero_grad()
    for p in D.parameters(): p.requires_grad = False
    
    G_loss = nn.BCELoss()(D(G(Z)), torch.ones((X.shape[0], 1)))

    G_loss.backward()
    G_optimizer.step()
    
    G_losses.append(G_loss.mean().item())
    D_losses.append(D_loss.mean().item())

    if i % 100 == 0:
      print(D_loss.mean().item(), G_loss.mean().item())

for epoch in range(100):
  print(epoch)
  train(G, D, G_optimizer, D_optimizer, train_loader)

def tensor2image(x):
  return x.detach().numpy().transpose(0, 2, 3, 1)

def image2tensor(x):
  return torch.tensor(x.transpose(0, 3, 1, 2))

def display_image(image):
  plt.figure(figsize=(1,1))
  plt.imshow(image[:,:,0], cmap = 'gray')
  plt.show()


transform = transforms.Compose([
  transforms.Normalize(mean=[0.5,],
                        std=[0.5,])])
inputs = torch.randn((10, 128))
print(inputs.shape)
predictions = G(inputs).cpu()
predictions_numpy = tensor2image(predictions.cpu())
for j, (inpt, prediction) in enumerate(zip(inputs, predictions_numpy)):
  print(inpt.sum(), prediction.sum())
  display_image(prediction)
  if j > 30:
    break

